{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing in c:\\users\\user\\anaconda3\\lib\\site-packages (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyparsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Group' from 'pyparsing' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisplay_images\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#Display images from the train dataset \u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Get the list of image files in the directory\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:129\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Don't let the original cycler collide with our validating cycler\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\_fontconfig_pattern.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lru_cache, partial\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyparsing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     Group, Optional, ParseException, Regex, StringEnd, Suppress, ZeroOrMore)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[0;32m     21\u001b[0m _family_punc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m-:,\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Group' from 'pyparsing' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def display_images(directory: str):\n",
    "    #Display images from the train dataset \n",
    "    # Get the list of image files in the directory\n",
    "    image_files = [f for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg', '.gif'))]\n",
    "\n",
    "    # Randomly select 'num_images' images\n",
    "    selected_images = random.sample(image_files, min(6, len(image_files)))\n",
    "\n",
    "    # Display each selected image\n",
    "    for image_file in selected_images:\n",
    "        image_path = os.path.join(directory, image_file)\n",
    "        img = Image.open(image_path)\n",
    "    # Display image using Matplotlib\n",
    "        plt.imshow(img)\n",
    "        plt.title(image_file)\n",
    "        plt.axis('off')  # Turn off axis labels\n",
    "        plt.show()\n",
    "\n",
    "def create_folder_and_move_files(file_list_path:str, folder_path:str):\n",
    "    \"\"\"\n",
    "    Used to organize data with a given file list and folder name.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created.\")\n",
    "\n",
    "    # Read the list of file names from the text file\n",
    "    with open(file_list_path, 'r') as file:\n",
    "        file_names = file.read().splitlines()\n",
    "\n",
    "    # Move the files to the new folder\n",
    "    for file_name in file_names:\n",
    "        source_path = os.path.abspath(file_name)\n",
    "        destination_path = os.path.join(folder_path, os.path.basename(file_name))\n",
    "\n",
    "        try:\n",
    "            shutil.move(source_path, destination_path)\n",
    "            print(f\"File '{file_name}' moved to '{folder_path}'.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File '{file_name}' not found in the current directory.\")\n",
    "        except (PermissionError, shutil.Error) as e:\n",
    "            print(f\"Error moving '{file_name}': {e}\")\n",
    "\n",
    "    print(\"All files moved successfully.\")\n",
    "\n",
    "def save_model(epochs, model, optimizer, criterion):\n",
    "    torch.save({\n",
    "        'epoch': epochs,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss':criterion\n",
    "    }, 'outputs/model.pth')\n",
    "\n",
    "def save_plots(train_acc, valid_acc, train_loss, valid_loss):\n",
    "    \"\"\"\n",
    "    Function to save the loss and accuracy plots to disk.\n",
    "    \"\"\"\n",
    "    # accuracy plots\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_acc, color='green', linestyle='-', \n",
    "        label='train accuracy'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_acc, color='blue', linestyle='-', \n",
    "        label='validataion accuracy'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('outputs/accuracy.png')\n",
    "    \n",
    "    # loss plots\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_loss, color='orange', linestyle='-', \n",
    "        label='train loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-', \n",
    "        label='validataion loss'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('outputs/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[0;32m      4\u001b[0m train_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/user/Desktop/LiverCirrhosisClassificationWebApp/liver_disease.v2-release.multiclass/train\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:533\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(_C):\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    535\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dir = 'C:/Users/user/Desktop/LiverCirrhosisClassificationWebApp/liver_disease.v2-release.multiclass/train'\n",
    "valid_dir = 'C:/Users/user/Desktop/LiverCirrhosisClassificationWebApp/liver_disease.v2-release.multiclass/valid'\n",
    "BATCH_SIZE = 32\n",
    "data_transform = transforms.Compose([\n",
    "        #transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "train_dataset = datasets.ImageFolder(root=train_dir,\n",
    "                                           transform=data_transform)\n",
    "train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "\n",
    "valid_dataset = datasets.ImageFolder(root=valid_dir,\n",
    "                                           transform=data_transform)\n",
    "valid_dataset_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                             batch_size=BATCH_SIZE, shuffle=False,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.functional\n",
    "import torch.nn.functional as F\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32,64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 4)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = self.pool(F.relu(self.conv3(x)))\n",
    "            x = self.pool(F.relu(self.conv4(x)))\n",
    "            \n",
    "            bs , _ , _, _ = x.shape\n",
    "            x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "            x = self.fc1(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from dataset import train_dataset_loader, valid_dataset_loader\n",
    "from model import SimpleClassifier\n",
    "#from utils import save_model, save_plots\n",
    "#TODO: use argparser to make it a command line thing\n",
    "lr = 1e-4\n",
    "EPOCHS = 30\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SimpleClassifier().to(device)\n",
    "print(model)\n",
    "print(f'Computation on: {device}')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, datasetloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    print('Training...')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    for i, data in tqdm(enumerate(datasetloader), total=len(datasetloader)):\n",
    "        image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (pred==labels).sum().item()\n",
    "        loss.backward() #Backprop\n",
    "        optimizer.step()\n",
    "        counter +=1\n",
    "    epoch_loss = train_running_loss/counter\n",
    "    epoch_acc = 100. *(train_running_correct / len(datasetloader.dataset))\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, datasetloader, criterion):\n",
    "    model.eval()\n",
    "    print('Validating...')\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(datasetloader), total=len(datasetloader)):\n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(image)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            val_running_correct += (pred == labels).sum().item()\n",
    "            counter += 1  # Increment counter\n",
    "    epoch_loss = val_running_loss / counter\n",
    "    epoch_acc = 100. * (val_running_correct / len(datasetloader.dataset))\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "valid_loss = []\n",
    "valid_acc = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch+1} of {EPOCHS}')\n",
    "    train_epoch_loss, train_epoch_acc = train(model, train_dataset_loader,\n",
    "                                               optimizer, criterion)\n",
    "    valid_epoch_loss, valid_epoch_acc = validate(model, valid_dataset_loader, criterion)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_acc.append(train_epoch_acc)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "    valid_acc.append(valid_epoch_acc)\n",
    "    print(f'Train Loss: {train_epoch_loss:.3f}, Train Accuracy: {train_epoch_acc:.3f}')\n",
    "    print(f'Validation Loss: {valid_epoch_loss:.3f}, Validation Accuracy: {valid_epoch_acc:.3f}')\n",
    "    print(\".\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
